{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install Python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /opt/app-root/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.16.2)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m191.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tf2onnx\n",
      "  Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m308.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras\n",
      "  Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m297.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m216.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting openvino-dev\n",
      "  Downloading openvino_dev-2024.4.0-16579-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m296.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20.2 in /opt/app-root/lib/python3.9/site-packages (from onnx->-r requirements.txt (line 1)) (4.25.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/app-root/lib/python3.9/site-packages (from onnx->-r requirements.txt (line 1)) (1.26.4)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m276.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m230.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/app-root/lib/python3.9/site-packages (from onnxruntime->-r requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from tf2onnx->-r requirements.txt (line 3)) (2.32.3)\n",
      "Collecting protobuf>=3.20.2\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m288.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/app-root/lib/python3.9/site-packages (from tf2onnx->-r requirements.txt (line 3)) (1.16.0)\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting ml-dtypes\n",
      "  Downloading ml_dtypes-0.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m306.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m186.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-3.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m252.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optree\n",
      "  Downloading optree-0.12.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m208.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich in /opt/app-root/lib/python3.9/site-packages (from keras->-r requirements.txt (line 4)) (12.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/app-root/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (4.12.2)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m220.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/app-root/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (69.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.3.0)\n",
      "Collecting ml-dtypes\n",
      "  Downloading ml_dtypes-0.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m296.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.16.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m279.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m197.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/app-root/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.66.0)\n",
      "Collecting tensorboard<2.18,>=2.17\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m284.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m173.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting networkx<=3.1.0\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m302.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.4.1 in /opt/app-root/lib/python3.9/site-packages (from openvino-dev->-r requirements.txt (line 6)) (6.0.2)\n",
      "Collecting openvino==2024.4.0\n",
      "  Downloading openvino-2024.4.0-16579-cp39-cp39-manylinux2014_x86_64.whl (42.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 MB\u001b[0m \u001b[31m267.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: defusedxml>=0.7.1 in /opt/app-root/lib/python3.9/site-packages (from openvino-dev->-r requirements.txt (line 6)) (0.7.1)\n",
      "Collecting openvino-telemetry>=2023.2.1\n",
      "  Downloading openvino_telemetry-2024.1.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/app-root/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 5)) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->tf2onnx->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->tf2onnx->-r requirements.txt (line 3)) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->tf2onnx->-r requirements.txt (line 3)) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->tf2onnx->-r requirements.txt (line 3)) (1.26.19)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m225.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m199.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m262.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m265.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/app-root/lib/python3.9/site-packages (from rich->keras->-r requirements.txt (line 4)) (2.18.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/app-root/lib/python3.9/site-packages (from rich->keras->-r requirements.txt (line 4)) (0.9.1)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m248.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.4 in /opt/app-root/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 5)) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/app-root/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 5)) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/app-root/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow->-r requirements.txt (line 5)) (3.20.1)\n",
      "Installing collected packages: openvino-telemetry, namex, mpmath, libclang, flatbuffers, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, sympy, protobuf, optree, opt-einsum, openvino, networkx, ml-dtypes, humanfriendly, h5py, google-pasta, gast, astunparse, absl-py, openvino-dev, markdown, keras, coloredlogs, tf2onnx, tensorboard, onnxruntime, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.4\n",
      "    Uninstalling protobuf-4.25.4:\n",
      "      Successfully uninstalled protobuf-4.25.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.2.1\n",
      "    Uninstalling networkx-3.2.1:\n",
      "      Successfully uninstalled networkx-3.2.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kfp 2.8.0 requires protobuf<5,>=4.21.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "kfp-pipeline-spec 0.3.0 requires protobuf<5,>=4.21.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "kfp-kubernetes 1.2.0 requires protobuf<5,>=4.21.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 astunparse-1.6.3 coloredlogs-15.0.1 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 h5py-3.11.0 humanfriendly-10.0 keras-3.5.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 mpmath-1.3.0 namex-0.0.8 networkx-3.1 onnxruntime-1.19.2 openvino-2024.4.0 openvino-dev-2024.4.0 openvino-telemetry-2024.1.0 opt-einsum-3.3.0 optree-0.12.1 protobuf-3.20.3 sympy-1.13.3 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 tf2onnx-1.16.1 werkzeug-3.0.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dependencies for the model training code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 11:13:29.847970: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-19 11:13:30.154311: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-19 11:13:30.413231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-19 11:13:30.931461: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-19 11:13:31.042497: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-19 11:13:31.212012: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-19 11:13:32.295294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>height_in_cms</th>\n",
       "      <th>digestive_disorder</th>\n",
       "      <th>type_of_workout</th>\n",
       "      <th>additional_activity</th>\n",
       "      <th>...</th>\n",
       "      <th>followed_diet_plan</th>\n",
       "      <th>taking_supplements</th>\n",
       "      <th>fitness_goal</th>\n",
       "      <th>target_weight</th>\n",
       "      <th>target_time_in_months</th>\n",
       "      <th>actual_calorie_intake_in_kcal_per_day</th>\n",
       "      <th>actual_carb_intake_in_gms</th>\n",
       "      <th>actual_protein_intake_in_gms</th>\n",
       "      <th>actual_fat_intake_in_gms</th>\n",
       "      <th>recommended_calorie_intake_in_kcal_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>Monday</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>86</td>\n",
       "      <td>154</td>\n",
       "      <td>No</td>\n",
       "      <td>Light Weight Training</td>\n",
       "      <td>Zumba</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2370</td>\n",
       "      <td>296</td>\n",
       "      <td>118</td>\n",
       "      <td>79</td>\n",
       "      <td>2296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>86</td>\n",
       "      <td>154</td>\n",
       "      <td>No</td>\n",
       "      <td>Calesthenics</td>\n",
       "      <td>Zumba</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1965</td>\n",
       "      <td>245</td>\n",
       "      <td>98</td>\n",
       "      <td>65</td>\n",
       "      <td>1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>86</td>\n",
       "      <td>154</td>\n",
       "      <td>No</td>\n",
       "      <td>Calesthenics</td>\n",
       "      <td>Zumba</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1695</td>\n",
       "      <td>211</td>\n",
       "      <td>84</td>\n",
       "      <td>56</td>\n",
       "      <td>1848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>86</td>\n",
       "      <td>154</td>\n",
       "      <td>No</td>\n",
       "      <td>Rest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1956</td>\n",
       "      <td>244</td>\n",
       "      <td>97</td>\n",
       "      <td>65</td>\n",
       "      <td>2136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>Friday</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>86</td>\n",
       "      <td>154</td>\n",
       "      <td>No</td>\n",
       "      <td>Light Weight Training</td>\n",
       "      <td>Zumba</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2141</td>\n",
       "      <td>267</td>\n",
       "      <td>107</td>\n",
       "      <td>71</td>\n",
       "      <td>2083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        date        day  age gender  weight  height_in_cms  \\\n",
       "0     1002  2022-01-03     Monday   37   Male      86            154   \n",
       "1     1002  2022-01-04    Tuesday   37   Male      86            154   \n",
       "2     1002  2022-01-05  Wednesday   37   Male      86            154   \n",
       "3     1002  2022-01-06   Thursday   37   Male      86            154   \n",
       "4     1002  2022-01-07     Friday   37   Male      86            154   \n",
       "\n",
       "  digestive_disorder        type_of_workout additional_activity  ...  \\\n",
       "0                 No  Light Weight Training               Zumba  ...   \n",
       "1                 No           Calesthenics               Zumba  ...   \n",
       "2                 No           Calesthenics               Zumba  ...   \n",
       "3                 No                   Rest                 NaN  ...   \n",
       "4                 No  Light Weight Training               Zumba  ...   \n",
       "\n",
       "   followed_diet_plan  taking_supplements fitness_goal target_weight  \\\n",
       "0                  No                  No  Weight Loss             6   \n",
       "1                  No                  No  Weight Loss             6   \n",
       "2                 Yes                  No  Weight Loss             6   \n",
       "3                 Yes                  No  Weight Loss             6   \n",
       "4                  No                  No  Weight Loss             6   \n",
       "\n",
       "  target_time_in_months actual_calorie_intake_in_kcal_per_day  \\\n",
       "0                     2                                  2370   \n",
       "1                     2                                  1965   \n",
       "2                     2                                  1695   \n",
       "3                     2                                  1956   \n",
       "4                     2                                  2141   \n",
       "\n",
       "   actual_carb_intake_in_gms  actual_protein_intake_in_gms  \\\n",
       "0                        296                           118   \n",
       "1                        245                            98   \n",
       "2                        211                            84   \n",
       "3                        244                            97   \n",
       "4                        267                           107   \n",
       "\n",
       "   actual_fat_intake_in_gms  recommended_calorie_intake_in_kcal_per_day  \n",
       "0                        79                                        2296  \n",
       "1                        65                                        1906  \n",
       "2                        56                                        1848  \n",
       "3                        65                                        2136  \n",
       "4                        71                                        2083  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Laoding the dataset\n",
    "Data = pd.read_csv('caloric_exp.csv')\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the input (X) and output (Y) data.\n",
    "\n",
    "X = Data.drop(columns = ['user_id','date','recommended_calorie_intake_in_kcal_per_day'])\n",
    "y = Data['recommended_calorie_intake_in_kcal_per_day']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets so you have something to test the trained model with.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path(\"artifact\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"artifact/test_data.pkl\", \"wb\") as handle:\n",
    "    pickle.dump((X_test, y_test), handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fetching the cols:\n",
    "num_cols = X_train.select_dtypes(include='number').columns.to_list()\n",
    "cat_cols = X_train.select_dtypes(exclude='number').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encoding the categorical_variables:\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(drop='first',handle_unknown='ignore',sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing the scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers = [('Encoder',OneHotEncoder(drop='first',handle_unknown='ignore',sparse_output=False),cat_cols),\n",
    "                    ('Scaler',StandardScaler(),num_cols)],\n",
    "                    remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ct_01= ct.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"artifact/column_transformer.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(ct_01, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "The model is a simple, fully-connected, deep neural network, containing three hidden layers and one output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_new = ct.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,185</span> (4.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,185\u001b[0m (4.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,185</span> (4.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,185\u001b[0m (4.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', input_dim = X_train_new.shape[1]))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(32))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(32))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['r2_score'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Training a model is often the most time-consuming part of the machine learning process.  Large models can take multiple GPUs for days.  Expect the training on CPU for this very simple model to take a minute or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5384427.5000 - r2_score: -41.9357 - val_loss: 5270675.0000 - val_r2_score: -42.7327\n",
      "Epoch 2/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5248821.5000 - r2_score: -42.4517 - val_loss: 5050319.5000 - val_r2_score: -40.9043\n",
      "Epoch 3/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5015870.5000 - r2_score: -38.5687 - val_loss: 4683843.0000 - val_r2_score: -37.8635\n",
      "Epoch 4/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4604520.0000 - r2_score: -36.6765 - val_loss: 4218434.0000 - val_r2_score: -34.0019\n",
      "Epoch 5/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4101503.0000 - r2_score: -32.0222 - val_loss: 3682675.2500 - val_r2_score: -29.5565\n",
      "Epoch 6/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3552860.0000 - r2_score: -27.8072 - val_loss: 3099851.5000 - val_r2_score: -24.7206\n",
      "Epoch 7/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2966506.0000 - r2_score: -22.8510 - val_loss: 2526038.7500 - val_r2_score: -19.9594\n",
      "Epoch 8/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2395042.2500 - r2_score: -18.2941 - val_loss: 1993772.1250 - val_r2_score: -15.5430\n",
      "Epoch 9/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1862156.6250 - r2_score: -14.4525 - val_loss: 1523311.3750 - val_r2_score: -11.6395\n",
      "Epoch 10/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1413263.3750 - r2_score: -10.1555 - val_loss: 1125333.2500 - val_r2_score: -8.3373\n",
      "Epoch 11/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1037427.7500 - r2_score: -7.3955 - val_loss: 803404.5000 - val_r2_score: -5.6661\n",
      "Epoch 12/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 727058.9375 - r2_score: -4.7938 - val_loss: 555999.7500 - val_r2_score: -3.6133\n",
      "Epoch 13/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 498303.0625 - r2_score: -3.0620 - val_loss: 376840.1875 - val_r2_score: -2.1268\n",
      "Epoch 14/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340162.7500 - r2_score: -1.7270 - val_loss: 256091.9062 - val_r2_score: -1.1249\n",
      "Epoch 15/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235224.0625 - r2_score: -0.8704 - val_loss: 180850.5156 - val_r2_score: -0.5006\n",
      "Epoch 16/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165161.0312 - r2_score: -0.3372 - val_loss: 137541.4531 - val_r2_score: -0.1412\n",
      "Epoch 17/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130358.0703 - r2_score: -0.0074 - val_loss: 114304.3594 - val_r2_score: 0.0516\n",
      "Epoch 18/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107752.8516 - r2_score: 0.1236 - val_loss: 101835.0781 - val_r2_score: 0.1550\n",
      "Epoch 19/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100663.6797 - r2_score: 0.2044 - val_loss: 94840.5781 - val_r2_score: 0.2131\n",
      "Epoch 20/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94107.8594 - r2_score: 0.2359 - val_loss: 90076.8203 - val_r2_score: 0.2526\n",
      "Epoch 21/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 87302.6797 - r2_score: 0.2748 - val_loss: 86171.8672 - val_r2_score: 0.2850\n",
      "Epoch 22/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 84554.2344 - r2_score: 0.3309 - val_loss: 82640.8516 - val_r2_score: 0.3143\n",
      "Epoch 23/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 80028.9922 - r2_score: 0.3718 - val_loss: 79261.4297 - val_r2_score: 0.3423\n",
      "Epoch 24/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78094.3281 - r2_score: 0.3664 - val_loss: 75948.6719 - val_r2_score: 0.3698\n",
      "Epoch 25/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75010.5312 - r2_score: 0.3839 - val_loss: 72694.4062 - val_r2_score: 0.3968\n",
      "Epoch 26/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71177.2188 - r2_score: 0.4271 - val_loss: 69445.2656 - val_r2_score: 0.4238\n",
      "Epoch 27/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65115.6406 - r2_score: 0.4795 - val_loss: 66283.5469 - val_r2_score: 0.4500\n",
      "Epoch 28/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63468.0430 - r2_score: 0.4813 - val_loss: 63197.1094 - val_r2_score: 0.4756\n",
      "Epoch 29/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60719.1562 - r2_score: 0.4963 - val_loss: 60199.1406 - val_r2_score: 0.5005\n",
      "Epoch 30/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59717.0898 - r2_score: 0.4989 - val_loss: 57344.9688 - val_r2_score: 0.5242\n",
      "Epoch 31/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54582.9727 - r2_score: 0.5557 - val_loss: 54570.8438 - val_r2_score: 0.5472\n",
      "Epoch 32/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51956.4453 - r2_score: 0.5658 - val_loss: 51949.9297 - val_r2_score: 0.5690\n",
      "Epoch 33/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48162.3633 - r2_score: 0.6116 - val_loss: 49463.0469 - val_r2_score: 0.5896\n",
      "Epoch 34/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46792.9141 - r2_score: 0.6182 - val_loss: 47092.5117 - val_r2_score: 0.6093\n",
      "Epoch 35/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45428.0430 - r2_score: 0.6434 - val_loss: 44872.9414 - val_r2_score: 0.6277\n",
      "Epoch 36/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43554.1328 - r2_score: 0.6545 - val_loss: 42817.9688 - val_r2_score: 0.6447\n",
      "Epoch 37/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40124.8516 - r2_score: 0.6724 - val_loss: 40918.6406 - val_r2_score: 0.6605\n",
      "Epoch 38/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38848.1328 - r2_score: 0.6898 - val_loss: 39154.8906 - val_r2_score: 0.6751\n",
      "Epoch 39/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37628.8477 - r2_score: 0.6943 - val_loss: 37549.7422 - val_r2_score: 0.6884\n",
      "Epoch 40/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35779.8086 - r2_score: 0.7074 - val_loss: 36058.6367 - val_r2_score: 0.7008\n",
      "Epoch 41/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34090.2422 - r2_score: 0.7267 - val_loss: 34683.9844 - val_r2_score: 0.7122\n",
      "Epoch 42/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32412.7539 - r2_score: 0.7398 - val_loss: 33415.2930 - val_r2_score: 0.7227\n",
      "Epoch 43/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32376.9043 - r2_score: 0.7344 - val_loss: 32294.3457 - val_r2_score: 0.7320\n",
      "Epoch 44/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29958.8574 - r2_score: 0.7461 - val_loss: 31268.9355 - val_r2_score: 0.7406\n",
      "Epoch 45/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29564.1211 - r2_score: 0.7659 - val_loss: 30290.8125 - val_r2_score: 0.7487\n",
      "Epoch 46/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28300.6914 - r2_score: 0.7744 - val_loss: 29426.3398 - val_r2_score: 0.7558\n",
      "Epoch 47/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27463.0410 - r2_score: 0.7829 - val_loss: 28625.4102 - val_r2_score: 0.7625\n",
      "Epoch 48/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27434.1016 - r2_score: 0.7797 - val_loss: 27886.3516 - val_r2_score: 0.7686\n",
      "Epoch 49/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27074.7168 - r2_score: 0.7776 - val_loss: 27200.4258 - val_r2_score: 0.7743\n",
      "Epoch 50/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24474.0938 - r2_score: 0.7968 - val_loss: 26554.6758 - val_r2_score: 0.7797\n",
      "Epoch 51/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25116.4141 - r2_score: 0.7982 - val_loss: 26013.8203 - val_r2_score: 0.7842\n",
      "Epoch 52/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23971.9414 - r2_score: 0.8065 - val_loss: 25416.2520 - val_r2_score: 0.7891\n",
      "Epoch 53/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23684.2852 - r2_score: 0.8129 - val_loss: 24866.5684 - val_r2_score: 0.7937\n",
      "Epoch 54/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23848.4355 - r2_score: 0.8070 - val_loss: 24365.4746 - val_r2_score: 0.7978\n",
      "Epoch 55/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24607.1641 - r2_score: 0.8054 - val_loss: 23891.2617 - val_r2_score: 0.8018\n",
      "Epoch 56/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21505.6309 - r2_score: 0.8277 - val_loss: 23424.4375 - val_r2_score: 0.8056\n",
      "Epoch 57/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22574.8711 - r2_score: 0.8143 - val_loss: 22956.6191 - val_r2_score: 0.8095\n",
      "Epoch 58/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21637.8027 - r2_score: 0.8247 - val_loss: 22480.0703 - val_r2_score: 0.8135\n",
      "Epoch 59/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21075.7402 - r2_score: 0.8315 - val_loss: 22052.2578 - val_r2_score: 0.8170\n",
      "Epoch 60/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21683.9258 - r2_score: 0.8251 - val_loss: 21607.3555 - val_r2_score: 0.8207\n",
      "Epoch 61/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20133.4375 - r2_score: 0.8362 - val_loss: 21194.8574 - val_r2_score: 0.8241\n",
      "Epoch 62/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19120.0391 - r2_score: 0.8428 - val_loss: 20754.0156 - val_r2_score: 0.8278\n",
      "Epoch 63/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19011.0762 - r2_score: 0.8446 - val_loss: 20377.6953 - val_r2_score: 0.8309\n",
      "Epoch 64/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19012.2246 - r2_score: 0.8448 - val_loss: 19949.4434 - val_r2_score: 0.8345\n",
      "Epoch 65/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18378.1543 - r2_score: 0.8501 - val_loss: 19568.7344 - val_r2_score: 0.8376\n",
      "Epoch 66/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18746.8770 - r2_score: 0.8499 - val_loss: 19205.5059 - val_r2_score: 0.8406\n",
      "Epoch 67/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18190.0391 - r2_score: 0.8514 - val_loss: 18850.8809 - val_r2_score: 0.8436\n",
      "Epoch 68/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17881.4609 - r2_score: 0.8571 - val_loss: 18444.9570 - val_r2_score: 0.8470\n",
      "Epoch 69/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17092.0742 - r2_score: 0.8571 - val_loss: 18097.7715 - val_r2_score: 0.8498\n",
      "Epoch 70/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16504.5664 - r2_score: 0.8661 - val_loss: 17777.0488 - val_r2_score: 0.8525\n",
      "Epoch 71/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16703.8828 - r2_score: 0.8634 - val_loss: 17413.4258 - val_r2_score: 0.8555\n",
      "Epoch 72/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16455.1309 - r2_score: 0.8704 - val_loss: 17122.6133 - val_r2_score: 0.8579\n",
      "Epoch 73/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16854.7188 - r2_score: 0.8647 - val_loss: 16783.5703 - val_r2_score: 0.8607\n",
      "Epoch 74/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16480.7285 - r2_score: 0.8718 - val_loss: 16435.1309 - val_r2_score: 0.8636\n",
      "Epoch 75/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15840.8037 - r2_score: 0.8739 - val_loss: 16165.7051 - val_r2_score: 0.8659\n",
      "Epoch 76/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15675.6416 - r2_score: 0.8721 - val_loss: 15841.5264 - val_r2_score: 0.8686\n",
      "Epoch 77/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14905.5752 - r2_score: 0.8796 - val_loss: 15559.1436 - val_r2_score: 0.8709\n",
      "Epoch 78/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15301.0762 - r2_score: 0.8745 - val_loss: 15262.0996 - val_r2_score: 0.8734\n",
      "Epoch 79/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14958.0537 - r2_score: 0.8811 - val_loss: 14992.0879 - val_r2_score: 0.8756\n",
      "Epoch 80/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13961.1904 - r2_score: 0.8862 - val_loss: 14739.6260 - val_r2_score: 0.8777\n",
      "Epoch 81/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13131.4834 - r2_score: 0.8926 - val_loss: 14467.6953 - val_r2_score: 0.8800\n",
      "Epoch 82/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13559.7568 - r2_score: 0.8965 - val_loss: 14174.3184 - val_r2_score: 0.8824\n",
      "Epoch 83/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13622.3887 - r2_score: 0.8860 - val_loss: 13929.5547 - val_r2_score: 0.8844\n",
      "Epoch 84/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13204.1670 - r2_score: 0.8932 - val_loss: 13683.9453 - val_r2_score: 0.8865\n",
      "Epoch 85/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13175.5830 - r2_score: 0.8937 - val_loss: 13454.4258 - val_r2_score: 0.8884\n",
      "Epoch 86/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12863.1250 - r2_score: 0.8987 - val_loss: 13208.9326 - val_r2_score: 0.8904\n",
      "Epoch 87/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12464.0977 - r2_score: 0.9013 - val_loss: 13003.7305 - val_r2_score: 0.8921\n",
      "Epoch 88/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12391.0195 - r2_score: 0.8969 - val_loss: 12751.6602 - val_r2_score: 0.8942\n",
      "Epoch 89/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11476.1025 - r2_score: 0.9061 - val_loss: 12520.5127 - val_r2_score: 0.8961\n",
      "Epoch 90/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11704.2637 - r2_score: 0.9040 - val_loss: 12296.8125 - val_r2_score: 0.8980\n",
      "Epoch 91/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12039.5908 - r2_score: 0.9008 - val_loss: 12092.1279 - val_r2_score: 0.8997\n",
      "Epoch 92/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11672.0264 - r2_score: 0.9068 - val_loss: 11878.1250 - val_r2_score: 0.9014\n",
      "Epoch 93/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11463.1113 - r2_score: 0.9095 - val_loss: 11680.7617 - val_r2_score: 0.9031\n",
      "Epoch 94/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11342.2520 - r2_score: 0.9079 - val_loss: 11468.4814 - val_r2_score: 0.9048\n",
      "Epoch 95/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10598.5684 - r2_score: 0.9159 - val_loss: 11286.8662 - val_r2_score: 0.9063\n",
      "Epoch 96/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10558.1758 - r2_score: 0.9158 - val_loss: 11092.5410 - val_r2_score: 0.9080\n",
      "Epoch 97/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10560.2393 - r2_score: 0.9128 - val_loss: 10908.8809 - val_r2_score: 0.9095\n",
      "Epoch 98/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10339.9531 - r2_score: 0.9144 - val_loss: 10710.3340 - val_r2_score: 0.9111\n",
      "Epoch 99/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9429.5459 - r2_score: 0.9244 - val_loss: 10524.0889 - val_r2_score: 0.9127\n",
      "Epoch 100/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9607.6270 - r2_score: 0.9222 - val_loss: 10401.6680 - val_r2_score: 0.9137\n",
      "Epoch 101/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9723.1611 - r2_score: 0.9199 - val_loss: 10175.1914 - val_r2_score: 0.9156\n",
      "Epoch 102/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9972.5820 - r2_score: 0.9220 - val_loss: 10004.7402 - val_r2_score: 0.9170\n",
      "Epoch 103/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9730.3291 - r2_score: 0.9191 - val_loss: 9846.1016 - val_r2_score: 0.9183\n",
      "Epoch 104/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9260.1406 - r2_score: 0.9257 - val_loss: 9697.8564 - val_r2_score: 0.9195\n",
      "Epoch 105/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9163.2607 - r2_score: 0.9270 - val_loss: 9550.5928 - val_r2_score: 0.9208\n",
      "Epoch 106/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8794.1865 - r2_score: 0.9293 - val_loss: 9361.4980 - val_r2_score: 0.9223\n",
      "Epoch 107/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8933.1836 - r2_score: 0.9259 - val_loss: 9225.4668 - val_r2_score: 0.9235\n",
      "Epoch 108/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8380.8896 - r2_score: 0.9319 - val_loss: 9081.9814 - val_r2_score: 0.9246\n",
      "Epoch 109/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8593.8193 - r2_score: 0.9301 - val_loss: 8899.5498 - val_r2_score: 0.9262\n",
      "Epoch 110/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8350.4268 - r2_score: 0.9327 - val_loss: 8772.4932 - val_r2_score: 0.9272\n",
      "Epoch 111/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8340.5342 - r2_score: 0.9324 - val_loss: 8631.8740 - val_r2_score: 0.9284\n",
      "Epoch 112/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8220.4541 - r2_score: 0.9322 - val_loss: 8492.9121 - val_r2_score: 0.9295\n",
      "Epoch 113/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8251.1406 - r2_score: 0.9365 - val_loss: 8359.4990 - val_r2_score: 0.9306\n",
      "Epoch 114/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7724.2363 - r2_score: 0.9374 - val_loss: 8210.5723 - val_r2_score: 0.9319\n",
      "Epoch 115/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8105.5806 - r2_score: 0.9334 - val_loss: 8093.8721 - val_r2_score: 0.9328\n",
      "Epoch 116/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7390.8457 - r2_score: 0.9408 - val_loss: 7955.8511 - val_r2_score: 0.9340\n",
      "Epoch 117/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7333.4258 - r2_score: 0.9403 - val_loss: 7835.5205 - val_r2_score: 0.9350\n",
      "Epoch 118/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7254.3286 - r2_score: 0.9416 - val_loss: 7686.7480 - val_r2_score: 0.9362\n",
      "Epoch 119/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7177.7539 - r2_score: 0.9414 - val_loss: 7598.7158 - val_r2_score: 0.9370\n",
      "Epoch 120/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7154.7544 - r2_score: 0.9420 - val_loss: 7465.8569 - val_r2_score: 0.9381\n",
      "Epoch 121/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7122.2065 - r2_score: 0.9435 - val_loss: 7341.4531 - val_r2_score: 0.9391\n",
      "Epoch 122/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6690.7129 - r2_score: 0.9450 - val_loss: 7215.2300 - val_r2_score: 0.9401\n",
      "Epoch 123/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6815.1455 - r2_score: 0.9441 - val_loss: 7125.6655 - val_r2_score: 0.9409\n",
      "Epoch 124/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6662.9023 - r2_score: 0.9462 - val_loss: 7009.7451 - val_r2_score: 0.9418\n",
      "Epoch 125/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6589.0020 - r2_score: 0.9472 - val_loss: 6923.4570 - val_r2_score: 0.9426\n",
      "Epoch 126/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6504.3193 - r2_score: 0.9468 - val_loss: 6800.8970 - val_r2_score: 0.9436\n",
      "Epoch 127/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6363.0005 - r2_score: 0.9489 - val_loss: 6672.6777 - val_r2_score: 0.9446\n",
      "Epoch 128/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6116.1812 - r2_score: 0.9505 - val_loss: 6584.6318 - val_r2_score: 0.9454\n",
      "Epoch 129/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5838.1597 - r2_score: 0.9507 - val_loss: 6489.7842 - val_r2_score: 0.9462\n",
      "Epoch 130/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6173.4663 - r2_score: 0.9483 - val_loss: 6375.9868 - val_r2_score: 0.9471\n",
      "Epoch 131/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6068.8818 - r2_score: 0.9502 - val_loss: 6292.5913 - val_r2_score: 0.9478\n",
      "Epoch 132/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5835.2910 - r2_score: 0.9521 - val_loss: 6212.3745 - val_r2_score: 0.9485\n",
      "Epoch 133/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5773.9468 - r2_score: 0.9524 - val_loss: 6113.9443 - val_r2_score: 0.9493\n",
      "Epoch 134/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5690.9067 - r2_score: 0.9535 - val_loss: 6019.7002 - val_r2_score: 0.9501\n",
      "Epoch 135/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5703.3403 - r2_score: 0.9548 - val_loss: 5940.8706 - val_r2_score: 0.9507\n",
      "Epoch 136/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5551.5186 - r2_score: 0.9554 - val_loss: 5843.5542 - val_r2_score: 0.9515\n",
      "Epoch 137/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5624.4409 - r2_score: 0.9558 - val_loss: 5787.5620 - val_r2_score: 0.9520\n",
      "Epoch 138/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5378.9604 - r2_score: 0.9557 - val_loss: 5695.6279 - val_r2_score: 0.9527\n",
      "Epoch 139/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5071.6060 - r2_score: 0.9589 - val_loss: 5613.0898 - val_r2_score: 0.9534\n",
      "Epoch 140/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5234.4917 - r2_score: 0.9581 - val_loss: 5535.9688 - val_r2_score: 0.9541\n",
      "Epoch 141/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5150.9907 - r2_score: 0.9587 - val_loss: 5458.6450 - val_r2_score: 0.9547\n",
      "Epoch 142/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4832.0605 - r2_score: 0.9598 - val_loss: 5396.3618 - val_r2_score: 0.9552\n",
      "Epoch 143/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5140.5518 - r2_score: 0.9588 - val_loss: 5312.0181 - val_r2_score: 0.9559\n",
      "Epoch 144/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4872.8452 - r2_score: 0.9615 - val_loss: 5253.3286 - val_r2_score: 0.9564\n",
      "Epoch 145/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4957.6191 - r2_score: 0.9601 - val_loss: 5197.7114 - val_r2_score: 0.9569\n",
      "Epoch 146/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4764.2686 - r2_score: 0.9614 - val_loss: 5117.5645 - val_r2_score: 0.9575\n",
      "Epoch 147/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4740.3369 - r2_score: 0.9611 - val_loss: 5034.7954 - val_r2_score: 0.9582\n",
      "Epoch 148/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4652.5625 - r2_score: 0.9624 - val_loss: 5008.7896 - val_r2_score: 0.9584\n",
      "Epoch 149/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4499.8896 - r2_score: 0.9615 - val_loss: 4942.1113 - val_r2_score: 0.9590\n",
      "Epoch 150/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4399.5933 - r2_score: 0.9641 - val_loss: 4846.6367 - val_r2_score: 0.9598\n",
      "Epoch 151/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4571.4302 - r2_score: 0.9632 - val_loss: 4809.4819 - val_r2_score: 0.9601\n",
      "Epoch 152/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4637.7764 - r2_score: 0.9635 - val_loss: 4758.9902 - val_r2_score: 0.9605\n",
      "Epoch 153/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4595.1240 - r2_score: 0.9631 - val_loss: 4689.7896 - val_r2_score: 0.9611\n",
      "Epoch 154/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4176.3359 - r2_score: 0.9660 - val_loss: 4636.8179 - val_r2_score: 0.9615\n",
      "Epoch 155/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4233.3491 - r2_score: 0.9663 - val_loss: 4581.1758 - val_r2_score: 0.9620\n",
      "Epoch 156/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4169.2607 - r2_score: 0.9667 - val_loss: 4556.2681 - val_r2_score: 0.9622\n",
      "Epoch 157/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4255.0728 - r2_score: 0.9656 - val_loss: 4473.1914 - val_r2_score: 0.9629\n",
      "Epoch 158/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4089.0354 - r2_score: 0.9671 - val_loss: 4435.9067 - val_r2_score: 0.9632\n",
      "Epoch 159/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4209.7485 - r2_score: 0.9675 - val_loss: 4401.7529 - val_r2_score: 0.9635\n",
      "Epoch 160/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4120.8403 - r2_score: 0.9657 - val_loss: 4349.8374 - val_r2_score: 0.9639\n",
      "Epoch 161/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3975.8018 - r2_score: 0.9689 - val_loss: 4309.9390 - val_r2_score: 0.9642\n",
      "Epoch 162/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3943.5776 - r2_score: 0.9678 - val_loss: 4247.4492 - val_r2_score: 0.9648\n",
      "Epoch 163/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3943.4644 - r2_score: 0.9681 - val_loss: 4211.7109 - val_r2_score: 0.9651\n",
      "Epoch 164/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3808.3684 - r2_score: 0.9693 - val_loss: 4175.5073 - val_r2_score: 0.9654\n",
      "Epoch 165/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3839.4617 - r2_score: 0.9696 - val_loss: 4153.9629 - val_r2_score: 0.9655\n",
      "Epoch 166/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3655.5911 - r2_score: 0.9717 - val_loss: 4102.2988 - val_r2_score: 0.9660\n",
      "Epoch 167/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3889.8228 - r2_score: 0.9679 - val_loss: 4060.8345 - val_r2_score: 0.9663\n",
      "Epoch 168/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3867.3250 - r2_score: 0.9694 - val_loss: 4016.5312 - val_r2_score: 0.9667\n",
      "Epoch 169/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3821.9980 - r2_score: 0.9691 - val_loss: 3984.7576 - val_r2_score: 0.9669\n",
      "Epoch 170/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3743.5300 - r2_score: 0.9701 - val_loss: 3949.3635 - val_r2_score: 0.9672\n",
      "Epoch 171/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3628.1338 - r2_score: 0.9705 - val_loss: 3913.0762 - val_r2_score: 0.9675\n",
      "Epoch 172/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3674.8052 - r2_score: 0.9698 - val_loss: 3869.7603 - val_r2_score: 0.9679\n",
      "Epoch 173/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3597.5305 - r2_score: 0.9703 - val_loss: 3851.5354 - val_r2_score: 0.9680\n",
      "Epoch 174/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3555.7200 - r2_score: 0.9715 - val_loss: 3819.8560 - val_r2_score: 0.9683\n",
      "Epoch 175/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3508.2515 - r2_score: 0.9713 - val_loss: 3803.0737 - val_r2_score: 0.9684\n",
      "Epoch 176/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3505.2695 - r2_score: 0.9719 - val_loss: 3767.0752 - val_r2_score: 0.9687\n",
      "Epoch 177/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3491.7812 - r2_score: 0.9716 - val_loss: 3747.5540 - val_r2_score: 0.9689\n",
      "Epoch 178/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3483.6311 - r2_score: 0.9718 - val_loss: 3714.2175 - val_r2_score: 0.9692\n",
      "Epoch 179/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3491.9568 - r2_score: 0.9720 - val_loss: 3696.4968 - val_r2_score: 0.9693\n",
      "Epoch 180/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3422.4609 - r2_score: 0.9718 - val_loss: 3647.4680 - val_r2_score: 0.9697\n",
      "Epoch 181/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3330.3916 - r2_score: 0.9738 - val_loss: 3640.1997 - val_r2_score: 0.9698\n",
      "Epoch 182/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3333.9397 - r2_score: 0.9726 - val_loss: 3617.9431 - val_r2_score: 0.9700\n",
      "Epoch 183/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3303.8953 - r2_score: 0.9737 - val_loss: 3574.7634 - val_r2_score: 0.9703\n",
      "Epoch 184/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3241.4968 - r2_score: 0.9723 - val_loss: 3544.2593 - val_r2_score: 0.9706\n",
      "Epoch 185/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3255.9226 - r2_score: 0.9741 - val_loss: 3538.5913 - val_r2_score: 0.9706\n",
      "Epoch 186/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3287.5947 - r2_score: 0.9729 - val_loss: 3506.4019 - val_r2_score: 0.9709\n",
      "Epoch 187/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3387.3218 - r2_score: 0.9727 - val_loss: 3478.6443 - val_r2_score: 0.9711\n",
      "Epoch 188/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3254.3142 - r2_score: 0.9745 - val_loss: 3481.7075 - val_r2_score: 0.9711\n",
      "Epoch 189/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3233.3503 - r2_score: 0.9746 - val_loss: 3449.7869 - val_r2_score: 0.9714\n",
      "Epoch 190/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3157.6228 - r2_score: 0.9754 - val_loss: 3425.1187 - val_r2_score: 0.9716\n",
      "Epoch 191/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3124.4624 - r2_score: 0.9750 - val_loss: 3415.1028 - val_r2_score: 0.9717\n",
      "Epoch 192/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3127.0210 - r2_score: 0.9751 - val_loss: 3379.9758 - val_r2_score: 0.9720\n",
      "Epoch 193/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3212.7307 - r2_score: 0.9746 - val_loss: 3355.5088 - val_r2_score: 0.9722\n",
      "Epoch 194/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3205.2263 - r2_score: 0.9753 - val_loss: 3357.8508 - val_r2_score: 0.9721\n",
      "Epoch 195/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3075.4385 - r2_score: 0.9753 - val_loss: 3320.6499 - val_r2_score: 0.9724\n",
      "Epoch 196/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3091.9678 - r2_score: 0.9743 - val_loss: 3316.0303 - val_r2_score: 0.9725\n",
      "Epoch 197/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3139.3848 - r2_score: 0.9750 - val_loss: 3293.7263 - val_r2_score: 0.9727\n",
      "Epoch 198/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3113.7039 - r2_score: 0.9742 - val_loss: 3287.7900 - val_r2_score: 0.9727\n",
      "Epoch 199/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3031.5918 - r2_score: 0.9760 - val_loss: 3252.0723 - val_r2_score: 0.9730\n",
      "Epoch 200/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3051.1731 - r2_score: 0.9764 - val_loss: 3268.9722 - val_r2_score: 0.9729\n",
      "Training of model is complete\n"
     ]
    }
   ],
   "source": [
    "# Train the model and get performance\n",
    "import os\n",
    "\n",
    "epochs = 200\n",
    "history = model.fit(X_train_new, y_train.values, epochs=epochs, \\\n",
    "                    validation_data=(ct.transform(X_val),y_val), \\\n",
    "                    verbose = True)\n",
    "print(\"Training of model is complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"models/caloric/1\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/caloric/1/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/caloric/1/my_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'models/caloric/1/my_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 35), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139776691596800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139776683029776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139776623920928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139776623920576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = \"models/caloric/1/my_model\"\n",
    "model.export(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] MO command line tool is considered as the legacy conversion API as of OpenVINO 2023.2 release.\n",
      "In 2025.0 MO command line tool and openvino.tools.mo.convert_model() will be removed. Please use OpenVINO Model Converter (OVC) or openvino.convert_model(). OVC represents a lightweight alternative of MO and provides simplified model conversion API. \n",
      "Find more information about transition from MO to OVC at https://docs.openvino.ai/2023.2/openvino_docs_OV_Converter_UG_prepare_model_convert_model_MO_OVC_transition.html\n",
      "[ INFO ] Generated IR will be compressed to FP16. If you get lower accuracy, please consider disabling compression explicitly by adding argument --compress_to_fp16=False.\n",
      "Find more information about compression to FP16 at https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_FP16_Compression.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /opt/app-root/src/calorie/models/caloric/1/saved_model.xml\n",
      "[ SUCCESS ] BIN file: /opt/app-root/src/calorie/models/caloric/1/saved_model.bin\n"
     ]
    }
   ],
   "source": [
    "!mo --saved_model_dir models/caloric/1/my_model --output_dir models/caloric/1 --framework tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test.dropna().sample(5).to_csv('X_test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'age', 'gender', 'weight', 'height_in_cms', 'digestive_disorder',\n",
       "       'type_of_workout', 'additional_activity', 'total_calories_burned',\n",
       "       'body_temperature', 'workout_intensity', 'followed_diet_plan',\n",
       "       'taking_supplements', 'fitness_goal', 'target_weight',\n",
       "       'target_time_in_months', 'actual_calorie_intake_in_kcal_per_day',\n",
       "       'actual_carb_intake_in_gms', 'actual_protein_intake_in_gms',\n",
       "       'actual_fat_intake_in_gms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tuesday', 30, 'Female', 43, 175, 'No', 'Calesthenics', nan, 272,\n",
       "       37, 'Low', 'Yes', 'No', 'Weight Gain', 17, 5, 1821, 227, 91, 60],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0,:].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "63462a1f26ab486248b2a0fd058a0d9f9a6566a80083a3e1eb8f35617f2381b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
